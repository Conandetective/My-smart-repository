#NLP技术简介

##jieba分词
**jieba分词** 是一款基于Trie树结构的中文分词工具。

其主要的处理思路如下：

1. 加载词典dict.txt
2. 从内存的词典中构建该句子的DAG（有向无环图）
3. 对于词典中未收录词，使用HMM模型的viterbi算法尝试分词处理
4. 已收录词和未收录词全部分词完毕后，使用dp寻找DAG的最大概率路径
5. 输出分词结果

*jieba分词在本项目中主要用于文本分词。*

##word2vec
**word2vec** 是word embedding（词向量）的一种浅层神经网络训练方法。

word2vec本质上来说就是一个矩阵分解的模型，简单地说，矩阵刻画了每个词和其上下文的词的集合的相关情况。对这个矩阵进行分解，只取每个词对应在隐含空间的向量。

所以word2vec适合的情况就是对于一个序列的数据，在序列局部数据间存在着很强的关联。典型的就是文本的序列了，邻近的词之间关联很强，甚至可以通过一个词的上下文大概预测出中间那个词是什么。学习到的词向量代表了词的语义，可以用来做分类、聚类、也可以做词的相似度计算。此外，Word2vec本身的层次分类器或者采样方式实际上对热门item做了很大的惩罚，所以不会像一般的矩阵分解一样，最后算出来语义接近的都是热门词，这也是word2vec很好的一个特性。

*word2vec在本项目中主要用于计算词语相似度，对同义词、相关词进行处理。*

##topic模型
**topic model** 是一种针对文本隐含主题的建模方法，主要用于：

- 计算文本的相似性，考虑到文本语义，更好的刻画文本相似性，避免多义词，同义词的影响
- 文本聚类，用户聚类(RS)
- 去除噪音，只保留最重要的主题，更好的刻画文档

*topic模型在本项目中主要用于进行文本聚类，对相同话题进行归纳。*

##KNN算法
**K近邻算法**（k Nearest Neighbors, kNN）是一种基于实例的学习，通过计算新数据与训练数据特征值之间的距离，然后选取K个距离最近的邻居进行分类判断。

kNN由3个要素决定： 

- 距离度量方法 
- k值 
- 分类决定规则

kNN算法的过程:

1. 选择一种距离度量方式, 通过所有的训练实例与输入实例的距离；
2. 将距离按递增次序进行排序，选取与当前距离最小的k个点；
3. 确定前k个点所在类别的出现频率；
4. 将出现频率最高的类别作为输入实例的预测分类。

*KNN算法在本项目中主要用于计算新数据与训练数据特征值之间的距离，并进行分类判断。*

##seq2seq(RNN)
**Seq2seq** 模型使用 RNN（此时被称为 encoder）将输入句子表示为一个向量， 再使用另一个 RNN（此时被称为 decoder）解码这个向量获取输出。如在英汉机 器翻译任务中，先使用 encoder RNN 处理英文句子获取语意向量，将该向量作为 decoder RNN 的初始输入，按顺序解码每个英文单词获取中文。

*同样的，如果将自然语言作为encoder，代码作为decoder进行训练，即可实现代码自动生成。*